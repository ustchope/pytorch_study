{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84cc6833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 304 ms (started: 2021-09-05 14:08:13 +08:00)\n"
     ]
    }
   ],
   "source": [
    "# 自动计算cell的计算时间\n",
    "%load_ext autotime\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='svg' #矢量图设置，让绘图更清晰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f98999",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# 增加更新\n",
    "git add *.ipynb */*.ipynb\n",
    "\n",
    "git remote -v\n",
    "\n",
    "git commit -m '更新 #3 Sept 05, 2021'\n",
    "\n",
    "#git push origin master\n",
    "git push"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cd0bba",
   "metadata": {},
   "source": [
    "在某些情况下，您可能希望跨不同设备保存和加载神经网络。\n",
    "\n",
    "# 介绍\n",
    "\n",
    "使用 PyTorch 跨设备保存和加载模型相对简单。 在这个秘籍中，我们将尝试跨 CPU 和 GPU 保存和加载模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c9e625",
   "metadata": {},
   "source": [
    "# 步骤\n",
    "* 导入所有必要的库以加载我们的数据\n",
    "* 定义并初始化神经网络\n",
    "* 保存在 GPU 上，加载到 CPU 上\n",
    "* 在 GPU 上保存，在 GPU 上加载\n",
    "* 在 CPU 上保存，在 GPU 上加载\n",
    "* 保存和加载 DataParallel 模型\n",
    "\n",
    "1. 导入必要的库来加载我们的数据\n",
    "\n",
    "对于这个秘籍，我们将使用 torch 及其子模块 torch.nn 和 torch.optim。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbd676e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 685 ms (started: 2021-09-05 14:09:57 +08:00)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1793594a",
   "metadata": {},
   "source": [
    "2. 定义并初始化神经网络\n",
    "\n",
    "例如，我们将创建一个用于训练图像的神经网络。 要了解更多信息，请参阅定义神经网络食谱。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cac5f48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "time: 30.1 ms (started: 2021-09-05 14:10:48 +08:00)\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c96fd69",
   "metadata": {},
   "source": [
    "3. 在GPU上保存，加载 CPU\n",
    "\n",
    "在使用 GPU 训练的 CPU 上加载模型时，将 torch.device('cpu') 传递给 torch.load() 函数中的 map_location 参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c61a3ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 15.4 ms (started: 2021-09-05 14:11:39 +08:00)\n"
     ]
    }
   ],
   "source": [
    "# 指定保存路径\n",
    "PATH = \"model.pt\"\n",
    "\n",
    "# Save\n",
    "torch.save(net.state_dict(), PATH)\n",
    "\n",
    "# Load\n",
    "device = torch.device('cpu')\n",
    "model = Net()\n",
    "model.load_state_dict(torch.load(PATH, map_location=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02331f73",
   "metadata": {},
   "source": [
    "在这种情况下，张量底层的存储使用 map_location 参数动态重新映射到 CPU 设备。\n",
    "\n",
    "4. 在 GPU 上保存，在 GPU 上加载\n",
    "\n",
    "在 GPU 上加载经过训练并保存在 GPU 上的模型时，只需使用 model.to(torch.device('cuda')) 将初始化模型转换为 CUDA 优化模型。\n",
    "\n",
    "请务必在所有模型输入上使用 .to(torch.device('cuda')) 函数来为模型准备数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0363edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "torch.save(net.state_dict(), PATH)\n",
    "\n",
    "# Load\n",
    "device = torch.device(\"cuda\")\n",
    "model = Net()\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e49b9af",
   "metadata": {},
   "source": [
    "5. CPU那个保存，加载 GPU\n",
    "\n",
    "在 GPU 上加载经过训练并保存在 CPU 上的模型时，将 torch.load() 函数中的 map_location 参数设置为 cuda:device_id。 这会将模型加载到给定的 GPU 设备。\n",
    "\n",
    "请务必调用 model.to(torch.device('cuda')) 将模型的参数张量转换为 CUDA 张量。\n",
    "\n",
    "最后，还要确保在所有模型输入上使用 .to(torch.device('cuda')) 函数来为 CUDA 优化模型准备数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde7a7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "torch.save(net.state_dict(), PATH)\n",
    "\n",
    "# Load\n",
    "device = torch.device(\"cuda\")\n",
    "model = Net()\n",
    "# Choose whatever GPU device number you want\n",
    "model.load_state_dict(torch.load(PATH, map_location=\"cuda:0\"))\n",
    "# Make sure to call input = input.to(device) on any input tensors that you feed to the model\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d29df4",
   "metadata": {},
   "source": [
    "6. 保存 torch.nn.DataParallel 模型\n",
    "\n",
    "torch.nn.DataParallel 是一个支持并行 GPU 使用的模型包装器。\n",
    "\n",
    "要一般地保存 DataParallel 模型，请保存 model.module.state_dict()。 这样，您就可以灵活地以任何方式将模型加载到您想要的任何设备上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0bf020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "torch.save(net.module.state_dict(), PATH)\n",
    "\n",
    "# Load to whatever device you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592b27fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch19]",
   "language": "python",
   "name": "conda-env-torch19-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
