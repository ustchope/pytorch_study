{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06c55e41",
   "metadata": {},
   "source": [
    "Captum 帮助您了解数据特征如何影响您的模型预测或神经元激活，揭示您的模型如何运作。\n",
    "\n",
    "使用 Captum，您可以统一应用各种最先进的特征归因算法，例如 Guided GradCam 和 Integrated Gradients。\n",
    "\n",
    "在这个秘籍中，您将学习如何使用 Captum 来： \n",
    "* 将图像分类器的预测归因于它们相应的图像特征。 \n",
    "* 可视化归因结果。\n",
    "\n",
    "# 在你开始之前\n",
    "\n",
    "确保 Captum 安装在活动的 Python 环境中。 Captum 可在 GitHub 上以 pip 包或 conda 包的形式使用。 有关详细说明，请参阅 https://captum.ai/ 上的安装指南\n",
    "\n",
    "对于模型，我们使用 PyTorch 中的内置图像分类器。 Captum 可以揭示样本图像的哪些部分支持模型做出的某些预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04b6a3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "model = torchvision.models.resnet18(pretrained=True).eval()\n",
    "\n",
    "response = requests.get(\"https://image.freepik.com/free-photo/two-beautiful-puppies-cat-dog_58409-6024.jpg\")\n",
    "img = Image.open(BytesIO(response.content))\n",
    "\n",
    "center_crop = transforms.Compose([\n",
    " transforms.Resize(256),\n",
    " transforms.CenterCrop(224),\n",
    "])\n",
    "\n",
    "normalize = transforms.Compose([\n",
    "    transforms.ToTensor(),               # converts the image to a tensor with values between 0 and 1\n",
    "    transforms.Normalize(                # normalize to follow 0-centered imagenet pixel rgb distribution\n",
    "     mean=[0.485, 0.456, 0.406],\n",
    "     std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "input_img = normalize(center_crop(img)).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4428ce0",
   "metadata": {},
   "source": [
    "# 计算归因\n",
    "\n",
    "在模型的前 3 个预测中是 208 和 283 类，它们对应于狗和猫。\n",
    "\n",
    "让我们使用 Captum 的遮挡算法将这些预测中的每一个归因于输入的相应部分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b06250d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import Occlusion\n",
    "\n",
    "occlusion = Occlusion(model)\n",
    "\n",
    "strides = (3, 9, 9)               # smaller = more fine-grained attribution but slower\n",
    "target=208,                       # Labrador index in ImageNet\n",
    "sliding_window_shapes=(3,45, 45)  # choose size enough to change object appearance\n",
    "baselines = 0                     # values to occlude the image with. 0 corresponds to gray\n",
    "\n",
    "attribution_dog = occlusion.attribute(input_img,\n",
    "                                       strides = strides,\n",
    "                                       target=target,\n",
    "                                       sliding_window_shapes=sliding_window_shapes,\n",
    "                                       baselines=baselines)\n",
    "\n",
    "\n",
    "target=283,                       # Persian cat index in ImageNet\n",
    "attribution_cat = occlusion.attribute(input_img,\n",
    "                                       strides = strides,\n",
    "                                       target=target,\n",
    "                                       sliding_window_shapes=sliding_window_shapes,\n",
    "                                       baselines=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d3d05d",
   "metadata": {},
   "source": [
    "除了遮挡之外，Captum 还具有许多算法，例如集成梯度、反卷积、GuidedBackprop、GradCam、DeepLift 和 GradientShap。 所有这些算法都是 Attribution 的子类，它期望您的模型在初始化时作为可调用的 forward_func 并具有以统一格式返回归因结果的 attribute(...) 方法。\n",
    "\n",
    "让我们对图像的计算归因结果进行可视化。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d38936",
   "metadata": {},
   "source": [
    "# 可视化结果\n",
    "\n",
    "Captum 的可视化实用程序提供了开箱即用的方法来可视化图片和文本输入的归因结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2484b080",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Image' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-3a97bfef79d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# negative attribution indicates distractor areas whose absence increases the score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m _ = viz.visualize_image_attr_multiple(attribution_dog,\n\u001b[0m\u001b[1;32m     13\u001b[0m                                       \u001b[0mcenter_crop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                                       \u001b[0mvis_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/miniconda3/envs/torch19/lib/python3.9/site-packages/captum/attr/_utils/visualization.py\u001b[0m in \u001b[0;36mvisualize_image_attr_multiple\u001b[0;34m(attr, original_image, methods, signs, titles, fig_size, use_pyplot, **kwargs)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethods\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m         visualize_image_attr(\n\u001b[0m\u001b[1;32m    410\u001b[0m             \u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m             \u001b[0moriginal_image\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moriginal_image\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/miniconda3/envs/torch19/lib/python3.9/site-packages/captum/attr/_utils/visualization.py\u001b[0m in \u001b[0;36mvisualize_image_attr\u001b[0;34m(attr, original_image, method, sign, plt_fig_axis, outlier_perc, cmap, alpha_overlay, show_colorbar, title, fig_size, use_pyplot)\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0;31m# Show original image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mImageVisualizationMethod\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mImageVisualizationMethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moriginal_image\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0moriginal_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m             \u001b[0moriginal_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0mplt_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Image' object has no attribute 'shape'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from captum.attr import visualization as viz\n",
    "\n",
    "# Convert the compute attribution tensor into an image-like numpy array\n",
    "attribution_dog = np.transpose(attribution_dog.squeeze().cpu().detach().numpy(), (1,2,0))\n",
    "\n",
    "vis_types = [\"heat_map\", \"original_image\"]\n",
    "vis_signs = [\"all\", \"all\"] # \"positive\", \"negative\", or \"all\" to show both\n",
    "# positive attribution indicates that the presence of the area increases the prediction score\n",
    "# negative attribution indicates distractor areas whose absence increases the score\n",
    "\n",
    "_ = viz.visualize_image_attr_multiple(attribution_dog,\n",
    "                                      center_crop(img),\n",
    "                                      vis_types,\n",
    "                                      vis_signs,\n",
    "                                      [\"attribution for dog\", \"image\"],\n",
    "                                      show_colorbar = True\n",
    "                                     )\n",
    "\n",
    "\n",
    "attribution_cat = np.transpose(attribution_cat.squeeze().cpu().detach().numpy(), (1,2,0))\n",
    "\n",
    "_ = viz.visualize_image_attr_multiple(attribution_cat,\n",
    "                                      center_crop(img),\n",
    "                                      [\"heat_map\", \"original_image\"],\n",
    "                                      [\"all\", \"all\"], # positive/negative attribution or all\n",
    "                                      [\"attribution for cat\", \"image\"],\n",
    "                                      show_colorbar = True\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9b5181",
   "metadata": {},
   "source": [
    "如果您的数据是文本数据，visualize.visualize_text() 提供了一个专门的视图来探索输入文本之上的属性。 在 http://captum.ai/tutorials/IMDB_TorchText_Interpret 了解更多信息"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44822597",
   "metadata": {},
   "source": [
    "# 最后的注意点\n",
    "\n",
    "Captum 可以处理 PyTorch 中的大多数模型类型，包括视觉、文本等。 使用 Captum，您可以： \n",
    "* 将特定输出归因于模型输入，如上所示。 \n",
    "* 将特定输出归因于隐藏层神经元（请参阅 Captum API 参考）。 \n",
    "* 将隐藏层神经元响应归因于模型输入（参见 Captum API 参考）。\n",
    "\n",
    "有关支持方法的完整 API 和教程列表，请访问我们的网站 http://captum.ai\n",
    "\n",
    "Gilbert Tanner 的另一篇有用的帖子：https://gilberttanner.com/blog/interpreting-pytorch-models-with-captum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2f2630",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch19]",
   "language": "python",
   "name": "conda-env-torch19-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
