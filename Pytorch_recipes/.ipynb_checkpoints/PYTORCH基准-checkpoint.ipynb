{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87e3a47f",
   "metadata": {},
   "source": [
    "本秘籍提供了使用PyTorch基准测试模块测量和比较代码性能的快速入门指南。\n",
    "\n",
    "# 介绍\n",
    "\n",
    "基准测试是写代码的重要步骤。它是验证我们的代码是否满足预期的性能方法，比较解决同一问题的不同并防止回归性能。\n",
    "\n",
    "在对 Pyorch 代码进行基准测试时有很多选择，包括 Python 内置的时间它模块。但是，对 PyTorch 代码进行基准测试有很多容易被注意事项，管理线程数量和同步 CUDA 设备。另外，为基准测试 生成 Tensor 输入可能非常乏味。\n",
    "\n",
    "这个秘籍演示了如何使用 PyTorch 基准测试模块来避免常见错误，同时更容易比较不同代码的性能、生成基准测试输入等。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701265bb",
   "metadata": {},
   "source": [
    "# 步骤\n",
    "1. 定义函数以进行基准测试\n",
    "2. 使用 timeit.Timer 进行基准测试\n",
    "3. 使用 torch.utils.benchmark.Timer 进行基准测试\n",
    "4. 使用阻塞式自动量程进行基准测试\n",
    "5. 比较基准结果\n",
    "6. 保存/加载基准测试结果\n",
    "7. 使用模糊参数生成输入\n",
    "8. 使用 Callgrind 收集指令计数\n",
    "\n",
    "1. 定义函数以进行基准测试\n",
    "\n",
    "在撰写本文时，torch.dot 不支持批处理模式，因此我们将比较使用现有 Torch 运算符实现它的两种方法：一种方法使用 mul 和 sum 的组合，而另一种方法将问题减少到 bmm。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "889543ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def batched_dot_mul_sum(a, b):\n",
    "    '''Computes batched dot by multiplying and summing'''\n",
    "    return a.mul(b).sum(-1)\n",
    "\n",
    "\n",
    "def batched_dot_bmm(a, b):\n",
    "    '''Computes batched dot by reducing to bmm'''\n",
    "    a = a.reshape(-1, 1, a.shape[-1])\n",
    "    b = b.reshape(-1, b.shape[-1], 1)\n",
    "    return torch.bmm(a, b).flatten(-3)\n",
    "\n",
    "\n",
    "# Input for benchmarking\n",
    "x = torch.randn(10000, 64)\n",
    "\n",
    "# Ensure that both functions compute the same output\n",
    "assert batched_dot_mul_sum(x, x).allclose(batched_dot_bmm(x, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61006b27",
   "metadata": {},
   "source": [
    "2. 使用 timeit.Timer 进行基准测试\n",
    "\n",
    "首先，让我们使用 Python 的内置 timeit 模块对代码进行基准测试。 我们在这里保持基准代码简单，以便我们可以比较 timeit 和 torch.utils.benchmark 的默认值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68e0bda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mul_sum(x, x):  123.0 us\n",
      "bmm(x, x):      122.9 us\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "t0 = timeit.Timer(\n",
    "    stmt='batched_dot_mul_sum(x, x)',\n",
    "    setup='from __main__ import batched_dot_mul_sum',\n",
    "    globals={'x': x})\n",
    "\n",
    "t1 = timeit.Timer(\n",
    "    stmt='batched_dot_bmm(x, x)',\n",
    "    setup='from __main__ import batched_dot_bmm',\n",
    "    globals={'x': x})\n",
    "\n",
    "print(f'mul_sum(x, x):  {t0.timeit(100) / 100 * 1e6:>5.1f} us')\n",
    "print(f'bmm(x, x):      {t1.timeit(100) / 100 * 1e6:>5.1f} us')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41d2205",
   "metadata": {},
   "source": [
    "3. 使用 torch.utils.benchmark.Timer 进行基准测试\n",
    "\n",
    "PyTorch 基准测试模块旨在让之前使用过 timeit 模块的人熟悉。 但是，它的默认设置使得用于对 PyTorch 代码进行基准测试更容易、更安全。 让我们首先比较与上面相同的基本 API。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e22fa1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.benchmark.utils.common.Measurement object at 0x7ff128c76bb0>\n",
      "batched_dot_mul_sum(x, x)\n",
      "setup: from __main__ import batched_dot_mul_sum\n",
      "  409.42 us\n",
      "  1 measurement, 100 runs , 1 thread\n",
      "<torch.utils.benchmark.utils.common.Measurement object at 0x7ff12d42fca0>\n",
      "batched_dot_bmm(x, x)\n",
      "setup: from __main__ import batched_dot_bmm\n",
      "  764.43 us\n",
      "  1 measurement, 100 runs , 1 thread\n"
     ]
    }
   ],
   "source": [
    "import torch.utils.benchmark as benchmark\n",
    "\n",
    "t0 = benchmark.Timer(\n",
    "    stmt='batched_dot_mul_sum(x, x)',\n",
    "    setup='from __main__ import batched_dot_mul_sum',\n",
    "    globals={'x': x})\n",
    "\n",
    "t1 = benchmark.Timer(\n",
    "    stmt='batched_dot_bmm(x, x)',\n",
    "    setup='from __main__ import batched_dot_bmm',\n",
    "    globals={'x': x})\n",
    "\n",
    "print(t0.timeit(100))\n",
    "print(t1.timeit(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49368c6e",
   "metadata": {},
   "source": [
    "尽管 API 的基本功能相同，但还是存在一些重要差异。 benchmark.Timer.timeit() 返回每次运行的时间，而不是像 timeit.Timer.timeit() 那样的总运行时间。 PyTorch 基准模块还提供用于打印结果的格式化字符串表示。\n",
    "\n",
    "另一个重要的区别，也是结果不同的原因是 PyTorch 基准测试模块默认在单线程中运行。 我们可以使用 num_threads 参数更改线程数。\n",
    "\n",
    "torch.utils.benchmark.Timer 需要几个额外的参数，包括：label、sub_label、description 和 env，它们改变了返回的测量对象的 __repr__ 并用于对结果进行分组（稍后会详细介绍）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e09177d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarking on 20 threads\n",
      "<torch.utils.benchmark.utils.common.Measurement object at 0x7ff1294ba220>\n",
      "Multithreaded batch dot: Implemented using mul and sum\n",
      "setup: from __main__ import batched_dot_mul_sum\n",
      "  84.94 us\n",
      "  1 measurement, 100 runs , 20 threads\n",
      "<torch.utils.benchmark.utils.common.Measurement object at 0x7ff1294ba700>\n",
      "Multithreaded batch dot: Implemented using bmm\n",
      "setup: from __main__ import batched_dot_bmm\n",
      "  107.02 us\n",
      "  1 measurement, 100 runs , 20 threads\n"
     ]
    }
   ],
   "source": [
    "num_threads = torch.get_num_threads()\n",
    "print(f'Benchmarking on {num_threads} threads')\n",
    "\n",
    "t0 = benchmark.Timer(\n",
    "    stmt='batched_dot_mul_sum(x, x)',\n",
    "    setup='from __main__ import batched_dot_mul_sum',\n",
    "    globals={'x': x},\n",
    "    num_threads=num_threads,\n",
    "    label='Multithreaded batch dot',\n",
    "    sub_label='Implemented using mul and sum')\n",
    "\n",
    "t1 = benchmark.Timer(\n",
    "    stmt='batched_dot_bmm(x, x)',\n",
    "    setup='from __main__ import batched_dot_bmm',\n",
    "    globals={'x': x},\n",
    "    num_threads=num_threads,\n",
    "    label='Multithreaded batch dot',\n",
    "    sub_label='Implemented using bmm')\n",
    "\n",
    "print(t0.timeit(100))\n",
    "print(t1.timeit(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39edac0c",
   "metadata": {},
   "source": [
    "使用所有可用线程运行基准测试给出与 timeit 模块类似的结果。 更重要的是，哪个版本更快取决于我们运行代码的线程数。 这就是为什么使用代表实际用例的线程设置对代码进行基准测试很重要的原因。 要记住的另一件重要事情是在 GPU 上进行基准测试时同步 CPU 和 CUDA。 让我们在 CUDA 张量上再次运行上述基准测试，看看会发生什么。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d6aabd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mul_sum(x, x):   40.3 us\n",
      "mul_sum(x, x):   36.2 us\n",
      "bmm(x, x):      985.3 us\n",
      "bmm(x, x):       45.8 us\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(10000, 1024, device='cuda:0')\n",
    "\n",
    "t0 = timeit.Timer(\n",
    "    stmt='batched_dot_mul_sum(x, x)',\n",
    "    setup='from __main__ import batched_dot_mul_sum',\n",
    "    globals={'x': x})\n",
    "\n",
    "t1 = timeit.Timer(\n",
    "    stmt='batched_dot_bmm(x, x)',\n",
    "    setup='from __main__ import batched_dot_bmm',\n",
    "    globals={'x': x})\n",
    "\n",
    "# Ran each twice to show difference before/after warmup\n",
    "print(f'mul_sum(x, x):  {t0.timeit(100) / 100 * 1e6:>5.1f} us')\n",
    "print(f'mul_sum(x, x):  {t0.timeit(100) / 100 * 1e6:>5.1f} us')\n",
    "print(f'bmm(x, x):      {t1.timeit(100) / 100 * 1e6:>5.1f} us')\n",
    "print(f'bmm(x, x):      {t1.timeit(100) / 100 * 1e6:>5.1f} us')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "827a3e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.benchmark.utils.common.Measurement object at 0x7ff12d42fbb0>\n",
      "batched_dot_mul_sum(x, x)\n",
      "setup: from __main__ import batched_dot_mul_sum\n",
      "  350.22 us\n",
      "  1 measurement, 100 runs , 1 thread\n",
      "<torch.utils.benchmark.utils.common.Measurement object at 0x7ff1294bacd0>\n",
      "batched_dot_bmm(x, x)\n",
      "setup: from __main__ import batched_dot_bmm\n",
      "  346.89 us\n",
      "  1 measurement, 100 runs , 1 thread\n"
     ]
    }
   ],
   "source": [
    "t0 = benchmark.Timer(\n",
    "    stmt='batched_dot_mul_sum(x, x)',\n",
    "    setup='from __main__ import batched_dot_mul_sum',\n",
    "    globals={'x': x})\n",
    "\n",
    "t1 = benchmark.Timer(\n",
    "    stmt='batched_dot_bmm(x, x)',\n",
    "    setup='from __main__ import batched_dot_bmm',\n",
    "    globals={'x': x})\n",
    "\n",
    "# Run only once since benchmark module does warmup for us\n",
    "print(t0.timeit(100))\n",
    "print(t1.timeit(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142106de",
   "metadata": {},
   "source": [
    "结果揭示了一些有趣的事情。 使用 timeit 模块的 bmm 版本的第一次运行比第二次运行要长得多。 这是因为 bmm 调用了 cuBLAS，它需要在第一次调用时加载，这需要一些时间。 这就是为什么在基准测试之前进行热身运行很重要的原因，对我们来说幸运的是，PyTorch 的基准测试模块会处理这个问题。\n",
    "\n",
    "timeit 和 benchmark 模块之间的结果差异是因为 timeit 模块不同步 CUDA，因此只计时启动内核的时间。 PyTorch 的 benchmark 模块为我们做同步。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494115ee",
   "metadata": {},
   "source": [
    "4. 使用阻塞式自动量程进行基准测试\n",
    "\n",
    "虽然 timeit.Timer.autorange 进行至少 0.2 秒的单次连续测量，但 torch.utils.benchmark.blocked_autorange 进行多次测量，其时间总计至少为 0.2 秒（可以通过 min_run_time 参数更改）受时间限制 开销只是整体测量的一小部分。 这是通过首先在每个循环中增加运行次数来实现的，直到运行时间远大于测量开销（这也用作预热），然后进行测量直到达到目标时间。 这具有有用的特性，即浪费更少的数据，并允许我们计算统计数据来估计测量的可靠性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7466f575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.benchmark.utils.common.Measurement object at 0x7ff1294ba1c0>\n",
      "batched_dot_mul_sum(x, x)\n",
      "setup: from __main__ import batched_dot_mul_sum\n",
      "  327.98 us\n",
      "  1 measurement, 1000 runs , 1 thread\n",
      "<torch.utils.benchmark.utils.common.Measurement object at 0x7ff1294baf70>\n",
      "batched_dot_bmm(x, x)\n",
      "setup: from __main__ import batched_dot_bmm\n",
      "  315.80 us\n",
      "  1 measurement, 1000 runs , 1 thread\n"
     ]
    }
   ],
   "source": [
    "m0 = t0.blocked_autorange()\n",
    "m1 = t1.blocked_autorange()\n",
    "\n",
    "print(m0)\n",
    "print(m1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d97d80",
   "metadata": {},
   "source": [
    "我们还可以从返回的测量对象中检查单个统计信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03fe15cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:   327.98 us\n",
      "Median: 327.98 us\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean:   {m0.mean * 1e6:6.2f} us\")\n",
    "print(f\"Median: {m0.median * 1e6:6.2f} us\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01625031",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64641fd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch19]",
   "language": "python",
   "name": "conda-env-torch19-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
